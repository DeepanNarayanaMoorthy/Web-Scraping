{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e87d9d-1fe4-436b-adcc-2258382fdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome.exe -remote-debugging-port=9014 --user-data-dir=\"C:\\Users\\deepa\\Desktop\\LinkedinExtract\\ChromeData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dde55-d31b-45e2-9f63-803e8605c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import requests\n",
    "import traceback\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e986dd-c590-4307-9abd-aef89f2dd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_debugging_port = 9014\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "options.add_experimental_option('debuggerAddress', 'localhost:9014')\n",
    "\n",
    "url=\"https://www.linkedin.com/jobs/search/?currentJobId=3628684746&distance=25&f_TPR=r86400&geoId=102713980&keywords=software&refresh=true&start=25\"\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\", options=options)\n",
    "driver.execute_cdp_cmd(\"Network.enable\", {})\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# sleep(2)\n",
    "# driver.find_element_by_name('session_key').send_keys(\"USEREMAIL\")\n",
    "# sleep(1)\n",
    "# driver.find_element_by_name('session_password').send_keys(\"USERPASSWORD\")\n",
    "\n",
    "element = WebDriverWait(driver, 20).until(\n",
    "EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/header/nav/div/a[2]')))\n",
    "\n",
    "element.click();\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.element_to_be_clickable((By.NAME, \"session_key\"))).send_keys('USEREMAIL')\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.element_to_be_clickable((By.NAME, \"session_password\"))).send_keys('USERPASSWORD')\n",
    "\n",
    "element = WebDriverWait(driver, 20).until(\n",
    "EC.element_to_be_clickable((By.XPATH, '//*[@id=\"organic-div\"]/form/div[3]/button')))\n",
    "\n",
    "element.click();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d70bcb-507a-4bcd-bc85-4a088bdbb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowscroller(driver):\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"main\"]/div/div[1]/div')))\n",
    "    # Scroll the element into view\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(element).perform()\n",
    "\n",
    "    # Slowly scroll the element using JavaScript\n",
    "    script = \"\"\"\n",
    "    var element = arguments[0];\n",
    "    var scrollHeight = element.scrollHeight;\n",
    "    var clientHeight = element.clientHeight;\n",
    "    var scrollStep = Math.ceil(scrollHeight / 100);\n",
    "\n",
    "    function scrollSlowly() {\n",
    "        if (element.scrollTop + clientHeight < scrollHeight) {\n",
    "            element.scrollTop += scrollStep;\n",
    "            setTimeout(scrollSlowly, 10);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scrollSlowly();\n",
    "    \"\"\"\n",
    "    driver.execute_script(script, element)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22ab37-bec8-4e48-a444-9d30d395522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagenumbers=[i for i in range(999) if i%25==0]\n",
    "filtered_links=[]\n",
    "for i in pagenumbers:\n",
    "    driver.get(f'https://www.linkedin.com/jobs/search/?currentJobId=3628684746&distance=25&f_TPR=r86400&geoId=102713980&keywords=software&refresh=true&start={i}')\n",
    "    scrollable_part = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"main\"]/div/div[1]/div')))\n",
    "    for i in range(5):\n",
    "        # driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_part)\n",
    "        slowscroller(driver)\n",
    "        sleep(1)\n",
    "    # slowscroller(driver)\n",
    "    links = driver.find_elements_by_tag_name(\"a\")\n",
    "    filtered_links=filtered_links+[link.get_attribute(\"href\") for link in links if \"/jobs/view\" in link.get_attribute(\"href\")]\n",
    "    print(len(filtered_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a5257-de0f-4e03-b8ec-2d4987518323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_substring(text, start_substring, end_substring):\n",
    "    start_index = text.find(start_substring)\n",
    "    if start_index == -1:\n",
    "        return ''\n",
    "    \n",
    "    start_index += len(start_substring)\n",
    "    end_index = text.find(end_substring, start_index)\n",
    "    if end_index == -1:\n",
    "        return ''\n",
    "    \n",
    "    return text[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1da2b-6e29-45fa-9a22-02981fc58d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_links\n",
    "filtered_codes=[]\n",
    "for i in filtered_links:\n",
    "    filtered_codes.append(extract_substring(i,'/jobs/view/','/?eBP='))\n",
    "filtered_codes=[i for i in filtered_codes if i!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d56bb3-1a59-4ab9-9b8b-86c03ad92b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99cd47-f8e3-422a-b68b-883adece971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicttsolve(dictt, key):\n",
    "    try:\n",
    "        return dictt[key]\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9d63f-a9cc-4650-b2ff-f5eab7f3423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "mainjsons=[]\n",
    "cookies = {'cookie_name': 'bcookie=\"v=2&853d89cf-2efd-4105-852a-ce343ee05781\"; bscookie=\"v=1&20221206065043a639f48c-9406-405b-875f-f5dd13258189AQGNGj5WI_RcJSXLHrhd2QD8jOGV16po\"; G_ENABLED_IDPS=google; aam_uuid=16662723610550796321673254091152595947; JSESSIONID=\"ajax:7665625736133769427\"; timezone=Asia/Calcutta; li_sugr=2eb504a4-954f-4f3e-96b4-417d2adabbd2; li_theme=dark; li_theme_set=user; _gcl_au=1.1.2097665459.1670577636; mbox=session#8c98c551e6ef40ebaa1e323d594ffef1#1678212699|PC#8c98c551e6ef40ebaa1e323d594ffef1.31_0#1693762839; _guid=c0fb0f13-b8be-4f6e-a6f7-0d751548e413; gpv_pn=www.linkedin.com%2Fpremium%2Fsurvey%2F; s_ips=837; s_tslv=1683890015601; s_tp=2794; AnalyticsSyncHistory=AQKMoDATLlLtygAAAYi6CsgaOd0_EFrSr5GveZWWkLV2EhzgJHqC2d2PoSWRE7rE_mvlJsMtArs1KZMr7IQmUQ; lms_ads=AQHAgV20ybFzIAAAAYi6Csj5aR1f9ztpU80RTWKzvfkVgNSsY8fv9lwnAgrgAp1IcE4b-Zky--_M6xvD6WNd1esOqA1nVKYE; lms_analytics=AQHAgV20ybFzIAAAAYi6Csj5aR1f9ztpU80RTWKzvfkVgNSsY8fv9lwnAgrgAp1IcE4b-Zky--_M6xvD6WNd1esOqA1nVKYE; li_at=AQEDASiK4OEEPQVgAAABiL9ppfUAAAGI43Yp9VYAYHIDmfrybgZk4Atm9YvPoOPBu19q_Mnnaf1wP7XzLU2d1jA42K2n5024o95gdG1erpkUgQgWR_EbJR7abtT4IMDkI2Ga7sIn-SQV8QlGA2b1RXqy; liap=true; lang=v=2&lang=en-us; AMCVS_14215E3D5995C57C0A495C55%40AdobeOrg=1; AMCV_14215E3D5995C57C0A495C55%40AdobeOrg=-637568504%7CMCIDTS%7C19525%7CMCMID%7C17161253032002680591727051875148916768%7CMCAAMLH-1687531715%7C12%7CMCAAMB-1687531715%7CRKhpRz8krg2tLO6pguXWp5olkAcUniQYPHaMWWgdJ3xzPWQmdj0y%7CMCOPTOUT-1686934115s%7CNONE%7CvVersion%7C5.1.1%7CMCCIDH%7C856016164; UserMatchHistory=AQIv9fOI7JBYFQAAAYjEsa_W1mWT7n8UzQLZdufqRAA0HRbmGI_WMjYwRqdGgzfHG9dxCIkH9C5H-LLO0kYzGN_LQBZTAF6Env4LracjVBf1iPf45rS-wMj-Y3bxTM2qENA4ilOSlPiCaA2FIpZmiM5plbQXSpEUhFOjvlOEgYMwGX2q0iv6szOx0M1zU1Rwf3fBBoKk1VnKndE6pNpssd_vjVLKP7wSAHaYi7gKJSCU6q3NRwpcodMXe72htIHOagH7YbzKa5dyonGyH0Nm-L0NWLlEWwsoJ1ipYwvBiSb-F-JHAVp4Y6u4oppdRio1KX-q8Xfz12t5iras4fQ466j2p0Bjecg; lidc=\"b=OB77:s=O:r=O:a=O:p=O:g=2790:u=508:x=1:i=1686927159:t=1686989618:v=2:sig=AQF6GluvD3Ef16FzcPSgVC4NKOSRZkvc\"; sdsc=22%3A1%2C1686928496075%7EJAPP%2C0y0bBBEk8jRaNt0Y7nV7iRCD50lY%3D'}\n",
    "csrf_token = 'ajax:7665625736133769427'  # Replace with your actual CSRF token\n",
    "headers = {'Csrf-Token': csrf_token}\n",
    "session.cookies.update(cookies)\n",
    "session.headers.update(headers)\n",
    "finaljson=[]\n",
    "for i in range(len(filtered_codes)):\n",
    "    try:\n",
    "        print(i, filtered_codes[i])\n",
    "        i=filtered_codes[i]\n",
    "        url = f\"https://www.linkedin.com/voyager/api/jobs/jobPostings/{i}\"\n",
    "        response = session.get(url)\n",
    "        asd=response.json()\n",
    "        mainjsons.append(asd)\n",
    "        print(response)\n",
    "        # dictt={'title':asd['title'],\n",
    "        #        'exp':asd['formattedExperienceLevel'],\n",
    "        #        'desc':asd['description']['text'],           \n",
    "        #        'link':\"https://www.linkedin.com/jobs/view/\"+str(i), ## asd['formattedEmploymentStatus']\n",
    "        #        'sourceDomain':asd['sourceDomain'],\n",
    "        #        'formattedIndustries':asd['formattedIndustries'],\n",
    "        #        'applicantTrackingSystem':asd['applicantTrackingSystem'],\n",
    "        #        'urlPathSegment':asd['urlPathSegment']\n",
    "        # }\n",
    "\n",
    "        dictt={'title':dicttsolve(asd,'title'),\n",
    "               'exp':dicttsolve(asd,'formattedExperienceLevel'),\n",
    "               'desc':dicttsolve(asd['description'],'text'),           \n",
    "               'link':\"https://www.linkedin.com/jobs/view/\"+str(i), ## dicttsolve(asd,'formattedEmploymentStatus')\n",
    "               'sourceDomain':dicttsolve(asd,'sourceDomain'),\n",
    "               'formattedIndustries':dicttsolve(asd,'formattedIndustries'),\n",
    "               'applicantTrackingSystem':dicttsolve(asd,'applicantTrackingSystem'),\n",
    "               'urlPathSegment':dicttsolve(asd,'urlPathSegment')\n",
    "        }\n",
    "        finaljson.append(dictt)\n",
    "        sleep(1)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    # print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d8f32-1128-4851-b84e-1750f2043c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_list(lst):\n",
    "#     flattened = []\n",
    "#     for item in lst:\n",
    "#         if isinstance(item, list):\n",
    "#             flattened.extend(flatten_list(item))\n",
    "#         else:\n",
    "#             flattened.append(item)\n",
    "#     return flattened\n",
    "\n",
    "# # for i in range(100):\n",
    "# #     desc=finaljson[i]['desc']\n",
    "# #     desc=desc.split(\"\\n\")\n",
    "# #     desc=flatten_list(desc)\n",
    "# #     desc=\" . \".join(desc)\n",
    "# #     desclist=desc.split(\".\")\n",
    "# #     desclist=[i for i in desclist if \"years\" in i or \"year\" in i or \"yrs\" in i]\n",
    "# #     print(desclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14fc0e-8331-47c4-b9ac-90e2a237c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_context_words(text, expected_word):\n",
    "    # Find all occurrences of the expected word in the text\n",
    "    occurrences = re.finditer(r'\\b{}\\b'.format(expected_word), text, re.IGNORECASE)\n",
    "    \n",
    "    context_words = []\n",
    "    for match in occurrences:\n",
    "        # Get the start and end indices of the match\n",
    "        start_index = match.start()\n",
    "        end_index = match.end()\n",
    "        \n",
    "        # Extract the three words before and after the expected word\n",
    "        words_before = text[max(start_index-20, 0):start_index].split()[-20:]\n",
    "        words_after = text[end_index:end_index+20].split()[:20]\n",
    "        \n",
    "        # Combine the words and add to the context_words list\n",
    "        context_words.append(words_before + [expected_word] + words_after)\n",
    "    \n",
    "    return context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bef42-069b-49a5-a407-838a565b9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcompanyname(name):\n",
    "    return extract_substring(name, '-at-','-3')\n",
    "def descyearextract(desc):\n",
    "    lis=[]\n",
    "    result = extract_context_words(desc, \"years\")\n",
    "    for words in result:\n",
    "        lis.append(\" \".join(words))\n",
    "    result = extract_context_words(desc, \"year\")\n",
    "    for words in result:\n",
    "        lis.append(\" \".join(words))\n",
    "    result = extract_context_words(desc, \"yrs\")\n",
    "    for words in result:\n",
    "        lis.append(\" \".join(words))\n",
    "    lis=list(set(lis))\n",
    "    return lis\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_numbers_from_sentence(sentence):\n",
    "    # Regular expression pattern to find numbers\n",
    "    pattern = r'\\b\\d+\\b'\n",
    "\n",
    "    # Find all numbers in the sentence\n",
    "    numbers = re.findall(pattern, sentence)\n",
    "\n",
    "    # Convert the numbers from string to integer or float\n",
    "    numbers = [int(num) if num.isdigit() else float(num) for num in numbers]\n",
    "\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d4a15-e21a-40e9-9f82-744725c205aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(finaljson)\n",
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d77c4-180f-4f70-9b14-f11c9bc09262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['company_name'] = [getcompanyname(i) for i in list(df['urlPathSegment'])]\n",
    "df2['years_extracted'] = [descyearextract(i) for i in list(df['desc'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051b3d4-d956-4cdc-ab92-575f79955b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['years_extracted']\n",
    "asdasd= [descyearextract(i) for i in list(df['desc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec213d0-7c3e-4ab0-bae8-6f199209c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrsnumslist=[]\n",
    "for i in asdasd:\n",
    "    yrsnumm=[]\n",
    "    for j in i:\n",
    "        yrsnumm.append(extract_numbers_from_sentence(j))\n",
    "    yrsnumslist.append(yrsnumm)\n",
    "        \n",
    "# df2['years_extracted'] = [descyearextract(i) for i in list(df['desc'])]\n",
    "df2['years_nums']=yrsnumslist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ca930-2b70-49b0-92f8-9532941bfbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[['title','company_name','link','exp','years_extracted','desc','sourceDomain','formattedIndustries','applicantTrackingSystem', 'years_nums']]\n",
    "df2.to_csv(\"Nested.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9e1d9-9477-4da4-a08f-69d02b1fba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ccf144-4db7-42c6-a63f-c1a99b42f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_nested_json_df(df):\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    \n",
    "    print(f\"original shape: {df.shape}\")\n",
    "    print(f\"original columns: {df.columns}\")\n",
    "    \n",
    "    \n",
    "    # search for columns to explode/flatten\n",
    "    s = (df.applymap(type) == list).all()\n",
    "    list_columns = s[s].index.tolist()\n",
    "    \n",
    "    s = (df.applymap(type) == dict).all()\n",
    "    dict_columns = s[s].index.tolist()\n",
    "    \n",
    "    print(f\"lists: {list_columns}, dicts: {dict_columns}\")\n",
    "    while len(list_columns) > 0 or len(dict_columns) > 0:\n",
    "        new_columns = []\n",
    "        \n",
    "        for col in dict_columns:\n",
    "            print(f\"flattening: {col}\")\n",
    "            # explode dictionaries horizontally, adding new columns\n",
    "            horiz_exploded = pd.json_normalize(df[col]).add_prefix(f'{col}.')\n",
    "            horiz_exploded.index = df.index\n",
    "            df = pd.concat([df, horiz_exploded], axis=1).drop(columns=[col])\n",
    "            new_columns.extend(horiz_exploded.columns) # inplace\n",
    "        \n",
    "        for col in list_columns:\n",
    "            print(f\"exploding: {col}\")\n",
    "            # explode lists vertically, adding new columns\n",
    "            df = df.drop(columns=[col]).join(df[col].explode().to_frame())\n",
    "            # Prevent combinatorial explosion when multiple\n",
    "            # cols have lists or lists of lists\n",
    "            df = df.reset_index(drop=True)\n",
    "            new_columns.append(col)\n",
    "        \n",
    "        # check if there are still dict o list fields to flatten\n",
    "        s = (df[new_columns].applymap(type) == list).all()\n",
    "        list_columns = s[s].index.tolist()\n",
    "\n",
    "        s = (df[new_columns].applymap(type) == dict).all()\n",
    "        dict_columns = s[s].index.tolist()\n",
    "        \n",
    "        print(f\"lists: {list_columns}, dicts: {dict_columns}\")\n",
    "        \n",
    "    print(f\"final shape: {df.shape}\")\n",
    "    print(f\"final columns: {df.columns}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d674bc-07da-425e-90d9-0a541724ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = flatten_nested_json_df(df2)\n",
    "df3.head()\n",
    "df3.to_csv(\"Normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819c397-ae85-4220-96da-4c7b2fbedf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaljson[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b58e6f-750f-445e-bac0-a9d12e6b1ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81b6c5-4a50-44a4-87d6-db341fdd08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "my_dict = defaultdict(list)\n",
    "\n",
    "for i in finaljson:\n",
    "    my_dict[i['applicantTrackingSystem']].append(getcompanyname(i['urlPathSegment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab832ed4-3dee-40e3-97f0-acd99c71179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(my_dict.keys()):\n",
    "    my_dict[i]=list(set(my_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd2855-cd2d-4142-88b9-d51c1cf94c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict['Lever']\n",
    "# my_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b983967-ddf9-4bee-aa75-c58f95ce503c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
