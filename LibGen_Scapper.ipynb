{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LibGen Scapper",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "6RY7UGS-jgOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "from google.colab import files, drive\n",
        "import re\n",
        "import string\n",
        "import wget, os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "NlYiGeZ-EL7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLEANING BOOK TOTLE TO BE ASSIGNED AS FILENAME FOR THE PDF\n",
        "def format_filename(s):\n",
        "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
        "    filename = ''.join(c for c in s if c in valid_chars)\n",
        "    filename = filename.replace(' ','_') # I don't like spaces in filenames.\n",
        "    return filename"
      ],
      "metadata": {
        "id": "nPYWbWKZHp8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTER WHATEVER SEARCH TERMS YOU WANT IN THE LIST BELOW\n",
        "searchterm=[\"Tensorflow packt\", \"nlp packt\", \"Natural Language processing packt\", \"deep learning packt\",\n",
        "            \"machine learning packt\", \"data science packt\", \"data analysis packt\"]\n",
        "searchterm=[i.replace(\" \",\"+\") for i in searchterm]\n",
        "namedictt=dict()\n",
        "for xx in searchterm:\n",
        "  try:\n",
        "    reqbase = \"http://libgen.is/search.php?&res=100&req=\" + xx + \"&page=\"\n",
        "    for i in range(20):\n",
        "      try:\n",
        "        req=reqbase+str(i)\n",
        "        html_page = urlopen(req)\n",
        "        soup = BeautifulSoup(html_page, \"lxml\")\n",
        "        asd=soup.findAll('a')\n",
        "        for link in soup.findAll('a'):\n",
        "          try:\n",
        "            #EXTRACTING ALL LINKS IN ALL PAGES OF SEARCH RESULTS FOR ALL SEARCH TERMS\n",
        "            namedictt[str(link.get('href'))]=link.contents[0]\n",
        "          except:\n",
        "            pass\n",
        "      except:\n",
        "        pass\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "fm61JPnLHsjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FILTERING ONLY THE BOOK LINKS ALONG WITH ITS TITLE\n",
        "links2={(\"http://libgen.is/\"+str(i)):format_filename(namedictt[i]) for i in namedictt.keys() if \"book/index.php?md5=\" in str(i)}\n",
        "print(links2)"
      ],
      "metadata": {
        "id": "bNEwZ7MmEfWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict2=dict()\n",
        "#FINDING THE URL FOR THE DOWNLOADS PAGE FOR ALL THE BOOKS\n",
        "for req in list(links2.keys()):\n",
        "  try:\n",
        "    html_page = urlopen(req)\n",
        "    soup = BeautifulSoup(html_page, \"lxml\")\n",
        "    inputTag = soup.find(\"a\", attrs={\"title\" : \"this mirror\"})\n",
        "    dict2[inputTag.get(\"href\")]=links2[req]\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "hl70yKMIEmyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict3=dict()\n",
        "#EXTRACTING DOWNLOAD LINK FOR CLOUDFLARE MIRROR FOR THE BOOKS\n",
        "for req in list(dict2.keys()):\n",
        "  try:\n",
        "    html_page = urlopen(req)\n",
        "    soup = BeautifulSoup(html_page, \"lxml\")\n",
        "    linkss=soup.findAll('a')\n",
        "    linkss=[i.get('href') for i in linkss]\n",
        "    linkss=[str(i) for i in linkss if \"https://cloudflare-ipfs.com\" in str(i)]\n",
        "    linkss=linkss[0]\n",
        "    dict3[str(linkss)]=dict2[req]\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "Fq7vR_hgJiB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FILTERING ONLY THE PDFS\n",
        "#YOU CAN CHOOSE WHATEVER THE EXTENSION YOU DESIRE AND REPLACE THE WORD \"pdf\" IN THE FOLLOWING LINE\n",
        "dict3={i:dict3[i] for i in list(dict3.keys()) if \"pdf\" in i}"
      ],
      "metadata": {
        "id": "FWwAawtUMCPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"books\")\n",
        "#DOWNLOADING ALL THE BOOKS\n",
        "for i in tqdm(list(dict4.keys())):\n",
        "  try:\n",
        "    wget.download(i, \"books/\"+dict3[i]+\".pdf\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "sjXxsq1qKpft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r books.zip books #ZIPPING THEM INTO A SINGLE FILE FOR DOWNLOAD\n",
        "!rm -rf books #REMOVING THE ORIGINAL FOLDER\n"
      ],
      "metadata": {
        "id": "ReLgwrZ-L3ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('books.zip')  #EITHER DOWNLOAD DIRECTLY\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/books.zip', 'w') as f: #OR COPY THE ZIPFILE TO DRIVE\n",
        "  f.write('/content/drive/MyDrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Y0xWof6dRRWn",
        "outputId": "d5f15760-1659-4ea3-add9-1a46dd904624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_db7e4abb-7497-4454-9082-7cdfaaa06e27\", \"books.zip\", 2634597898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}